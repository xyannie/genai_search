{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encyclopedia P.O.C\n",
    "\n",
    "This notebook is dedicated to exploring the usage of GENAI to develop encyclopedic facts based on search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import re\n",
    "import os\n",
    "import emoji\n",
    "import json\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CONSTANTS\n",
    "\n",
    "ENCYCLOPEDIA_PROMPT = \"\"\"\n",
    "A user searches the following query on the MoneyLion app\n",
    "search_query : {search_query}\n",
    "Instructions:\n",
    "Generate an educative fun fact about {search_query} without mentioning any specific company, like Starbucks.\n",
    "This fact can be a piece of advice, a fun fact or a statistic.\n",
    "Provide the source of the fact such as the name of the website or the name of the book.\n",
    "\n",
    "Strict constraints:\n",
    "    If the search query is a name of a company or brand, generated_fact must return \"Company or brand name, no fact generated\".\n",
    "    Do not produce a fact that can negatively impact MoneyLion's brand or reputation.\n",
    "    Do not provide alternatives to MoneyLion's products or services.\n",
    "    The output must not contain any company names or brand names.\n",
    "\n",
    "Output criteria:\n",
    "    - return final answer using 3 variables \"generated_fact\", \"source\" and \"fact_type\"\n",
    "    - compute \"generated_fact\" as: generated fact\n",
    "    - compute \"source\" as: source of the fact\n",
    "    - compute \"fact_type\" as: type of fact (fun fact, statistic, advice)\n",
    "    - output final answer in the following format:\n",
    "        generated_fact=(input value of generated_fact here); source=(input value of source here); fact_type=(input value of fact_type here)\n",
    "\n",
    "Performance Evaluation:\n",
    "1. Never, never return search query or the generated_fact that will contains any specific company names or brand names (e.g. Starbucks, Chime, etc.)\n",
    "2. As mentioned, in the case above, just return \"Company or brand name, no fact generated\"\n",
    "\"\"\"\n",
    "\n",
    "PRODUCT_KEYWORDS = [\n",
    "    'Roar Money',\n",
    "    'Instacash',\n",
    "    'Credit Builder Plus'\n",
    "]\n",
    "\n",
    "PRODUCT_ACTION_KEYWORDS = [\n",
    "    'Peer Boost',\n",
    "    'Shake n Bank',\n",
    "    'Cash Advance',\n",
    "]\n",
    "\n",
    "COMPETITOR_KEYWORDS = [\n",
    "    \"SoFi\",\n",
    "    \"Cleo\",\n",
    "    \"Mission Lane\",\n",
    "    \"Propel\",\n",
    "    \"Dave\",\n",
    "    \"Braviant Holdings\",\n",
    "    \"EarnIn\",\n",
    "    \"Brigit\",\n",
    "    \"Affirm\",\n",
    "    \"Avant\",\n",
    "    \"Varo\",\n",
    "    \"Revolut\",\n",
    "    \"Monso\",\n",
    "    \"Acorn\",\n",
    "    \"Betterment\",\n",
    "    \"Chime\",\n",
    "]\n",
    "\n",
    "GENERATED_FACT_PATTERN = r\"generated_fact=(.*?);\"\n",
    "CATEGORY_PATTERN = r\"category=(.*?);\"\n",
    "SOURCE_PATTERN = r\"source=(.*?);\"\n",
    "FACT_TYPE_PATTERN = r\"fact_type=(.*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING FUNCTION USED FOR BOTH PRE AND POST PROCESSING\n",
    "def check_keywords(query):\n",
    "    \"\"\"\n",
    "    Check if the query contains any of the product keywords.\n",
    "    Used for both pre and post processing steps\n",
    "\n",
    "    params:\n",
    "        query: the query to be checked\n",
    "    \n",
    "    returns:\n",
    "        True if the query contains any of the product keywords\n",
    "        False otherwise\n",
    "    \"\"\"\n",
    "    keyword_list = PRODUCT_KEYWORDS + PRODUCT_ACTION_KEYWORDS + COMPETITOR_KEYWORDS\n",
    "    for keyword in keyword_list:\n",
    "        if keyword.lower() in query.lower() or keyword.lower().replace(' ', '') in query.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATION FUNCTIONS\n",
    "def get_gpt_response(prompt, temperature=1.0, model = \"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    To generate content using GPT\n",
    "    We use the GPT-3.5-turbo model for generating content\n",
    "    For offline testing however, we use GPT 4 for generating the evaluation score\n",
    "\n",
    "    params:\n",
    "        prompt: the prompt to be used for generating content\n",
    "        temperature: the temperature to be used for generating content/evaluation score\n",
    "        model: the model to be used for generating content/evaluation score\n",
    "\n",
    "    returns:\n",
    "        response: the response from the GPT API\n",
    "    \"\"\"\n",
    "    CHAT_COMPLETION_MODEL = model\n",
    "    CHAT_COMPLETION_API_PARAMS = {\n",
    "        \"temperature\": temperature,\n",
    "        \"model\": CHAT_COMPLETION_MODEL,\n",
    "    }\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages=messages, **CHAT_COMPLETION_API_PARAMS\n",
    "    )\n",
    "\n",
    "    response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return response, response_content\n",
    "\n",
    "\n",
    "def main_generate_fact (query):\n",
    "    \"\"\"\n",
    "    Executes the following steps:\n",
    "        1. Check if the query contains any of the product keywords\n",
    "        2. If no, generate the fact using GPT. If yes, return None\n",
    "        3. Post process the generated fact\n",
    "\n",
    "    params:\n",
    "        query: the query to be checked\n",
    "\n",
    "    returns:\n",
    "        fact: the generated output   \n",
    "    \"\"\"\n",
    "    prompt = ENCYCLOPEDIA_PROMPT.format(search_query=query)\n",
    "    response, fact = get_gpt_response(prompt)\n",
    "    \n",
    "    return fact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-PROCESSING FUNCTIONS\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"\n",
    "    Remove all emojis in title\n",
    "\n",
    "    params:\n",
    "        text: the text to be cleaned\n",
    "    \n",
    "    returns:\n",
    "        cleaned_text: the cleaned text\n",
    "    \"\"\"\n",
    "    cleaned_text = ''\n",
    "    for words in text:\n",
    "        if words not in emoji.EMOJI_DATA:\n",
    "            cleaned_text += words\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    \"\"\"\n",
    "    Remove leading and trailing whitespace and newline characters, exclamation marks (!), and quotation marks (\") from the text.\n",
    "\n",
    "    params:\n",
    "        text: the text to be cleaned\n",
    "\n",
    "    returns:\n",
    "        cleaned_text: the cleaned text\n",
    "    \"\"\"\n",
    "    text = text.strip(\" \\n\")\n",
    "    t1 = re.sub(\"\\s*!\\s*\", repl=\"\", string=text)\n",
    "    t2 = re.sub('\\s*\"\\s*', repl=\"\", string=t1)\n",
    "    t3 = re.sub(\"\\s*“\\s*\", repl=\"\", string=t2)\n",
    "    t4 = re.sub(\"\\s*”\\s*\", repl=\"\", string=t3)\n",
    "\n",
    "    return t4\n",
    "\n",
    "def extract_generation_output(text):\n",
    "    \"\"\"\n",
    "    Extract the generated fact, source and type of fact from the response content\n",
    "\n",
    "    params:\n",
    "        response_content: the generated content to be extracted\n",
    "    \n",
    "    returns:\n",
    "        generated_fact: the generated fact\n",
    "        source: the source of the fact\n",
    "        type_of_fact: the type of fact\n",
    "    \"\"\"\n",
    "\n",
    "    # generated_fact = re.findall(GENERATED_FACT_PATTERN, response_content)[0]\n",
    "    # source = re.findall(SOURCE_PATTERN, response_content)[0]\n",
    "    # type_of_fact = re.findall(TYPE_OF_FACT_PATTERN, response_content)[0]\n",
    "\n",
    "    try:\n",
    "        generated_fact = re.search(GENERATED_FACT_PATTERN, text).group(1)\n",
    "        # category = re.search(CATEGORY_PATTERN, text).group(1)\n",
    "        source = re.search(SOURCE_PATTERN, text).group(1)\n",
    "        fact_type = re.search(FACT_TYPE_PATTERN, text).group(1)\n",
    "        # if generated_fact and source and category and fact_type:\n",
    "        #     return generated_fact, category, source, fact_type\n",
    "        if generated_fact and source and fact_type:\n",
    "            return generated_fact, source, fact_type\n",
    "    except Exception as error:\n",
    "        print(\"Error in extracting generation output\")\n",
    "        print(error)\n",
    "\n",
    "def check_entity_words (text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    if [(e.text, e.label_) for e in doc.ents if e.label_ in ('ORG')]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def post_process_fact(text):\n",
    "    \"\"\"\n",
    "    Post process the fact to remove unnecessary characters and emojis\n",
    "\n",
    "    params:\n",
    "        text: the text to be cleaned\n",
    "\n",
    "    returns:\n",
    "        cleaned_text: the cleaned text\n",
    "    \"\"\"\n",
    "    t1 = remove_unnecessary_char(text)\n",
    "    t2 = remove_emojis(t1)\n",
    "    generated_fact, source, type_of_fact = extract_generation_output(t2)\n",
    "    entity_flag = check_entity_words(generated_fact)\n",
    "    keywords_flag = check_keywords(generated_fact)\n",
    "    flag = entity_flag or keywords_flag\n",
    "\n",
    "    return generated_fact, source, type_of_fact, flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION FUNCTIONS - NOT TO BE DEPLOYED FOR PRODUCTION\n",
    "\n",
    "def extract_evaluation_results(evaluation_response):\n",
    "    \"\"\"\n",
    "    Extract the evaluation metrics and their results from the evaluation response\n",
    "\n",
    "    params:\n",
    "        evaluation_response: the response from GPT-4 output\n",
    "    \n",
    "    returns:\n",
    "        r1: result_rating\n",
    "        r2: result_relevance\n",
    "        r3: source_credibility\n",
    "        r4: rating_reason\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        r1 = re.search(r\"result_rating=([0-9]+)\", evaluation_response).groups()[0]\n",
    "        r2 = re.search(r\"result_relevance=([0-1])\", evaluation_response).groups()[0]\n",
    "        r3 = re.search(r\"source_credibility=([0-1])\", evaluation_response).groups()[0]\n",
    "        r4 = re.search(r\"rating_reason=(.*)\", evaluation_response).groups()[0]\n",
    "        if r1 and r2 and r3 and r4:\n",
    "            break\n",
    "    return r1, r2, r3, r4\n",
    "\n",
    "\n",
    "def main_evaluate_fact(query, fact):\n",
    "    \"\"\"\n",
    "    Evaluate the generated fact using GPT-4 with the following criteria:\n",
    "        - Is the fact generated related to the query?\n",
    "        - Is the source of the fact credible?\n",
    "    \n",
    "    params:\n",
    "        query: the query to be checked\n",
    "        fact: the generated fact\n",
    "    \n",
    "    returns:\n",
    "        result_rating: the rating of the fact generated\n",
    "        result_relevance: the relevance of the fact generated\n",
    "        source_credibility: the credibility of the source of the fact generated\n",
    "        rating_reason: the reasoning of the rating\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = EVALUATION_PROMPT.format(search_query=query, fact=fact)\n",
    "    response, evaluation_response_content = get_gpt_response(prompt, model=\"gpt-4\")\n",
    "    if evaluation_response_content:\n",
    "        result_rating, result_relevance, source_credibility, rating_reason = extract_evaluation_results(evaluation_response_content)\n",
    "    return result_rating, result_relevance, source_credibility, rating_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single input test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_fact=To apply for a loan, it is important to have a good credit score. Lenders often use credit scores to determine loan eligibility and interest rates.; source=www.investopedia.com; fact_type=advice\n",
      "{\"query\": \"how to apply loan\", \"fact\": \"To apply for a loan, it is important to have a good credit score. Lenders often use credit scores to determine loan eligibility and interest rates.\", \"source\": \"www.investopedia.com\", \"fact_type\": \"advice\", \"hide_flag\": false}\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter query: \")\n",
    "fact = main_generate_fact(query)\n",
    "print(fact)\n",
    "if fact is not None:\n",
    "    # Evaluation\n",
    "        # result_rating, result_relevance, source_credibility, rating_reason = main_evaluate_fact(query, fact)\n",
    "    # generated_fact, category, source, type_of_fact = post_process_fact(fact)\n",
    "    generated_fact, source, type_of_fact, flag = post_process_fact(fact)\n",
    "    # check if generated fact contains entity\n",
    "    json_response = {\n",
    "        \"query\": query,\n",
    "        \"fact\": generated_fact, \n",
    "        \"source\": source,\n",
    "        \"fact_type\": type_of_fact,\n",
    "        \"hide_flag\": flag\n",
    "    } \n",
    "    output = json.dumps(json_response)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope Test - Run seperately\n",
    "\n",
    "#### Test Dataset used : Google's Top Financial and Economy Search terms in the Past 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataset = pd.read_csv('../../input/search_sample_queries.csv')\n",
    "# #only get random 50 queries\n",
    "# df_dataset = df_dataset.sample(n=50)\n",
    "# df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df_dataset.iterrows():\n",
    "#     query = row['Top 100 Queries & Suggestions']\n",
    "#     category = 'Universal Search Sample'\n",
    "#     if query in df_dataset['Query'].values:\n",
    "#         continue\n",
    "#     fact,flag = main_generate_fact(query)\n",
    "#     if fact is not None:\n",
    "#         # Evaluation\n",
    "#             # result_rating, result_relevance, source_credibility, rating_reason = main_evaluate_fact(query, fact)\n",
    "#         if flag == 0:\n",
    "#             generated_fact = re.findall(GENERATED_FACT_PATTERN, fact)[0]\n",
    "#             source = re.findall(SOURCE_PATTERN, fact)[0]\n",
    "#             type_of_fact = re.findall(TYPE_OF_FACT_PATTERN, fact)[0]\n",
    "#         else:\n",
    "#             generated_fact = \"Query contains restricted keywords\"\n",
    "#             source = None\n",
    "#             type_of_fact = None\n",
    "#         json_response = {\n",
    "#             \"query\": query,\n",
    "#             \"fact\": generated_fact, \n",
    "#             \"source\": source,\n",
    "#             \"fact_type\": type_of_fact,\n",
    "#             \"hide_flag\": flag\n",
    "#         } \n",
    "#         output = json.dumps(json_response)\n",
    "#         print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate the length of query\n",
    "# df_dataset['Query_Length'] = df_dataset['Query'].str.len()\n",
    "# df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df.to_csv('../../output/financial_economy_query_dataset_output.csv', index=False)\n",
    "# df_dataset.to_csv('../../output/moneylion_search_queries_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHIVED CONSTANTS\n",
    "\n",
    "# ENCYCLOPEDIA_PROMPT_2 = \"\"\"\n",
    "# A user searches the following query on the MoneyLion app\n",
    "# search_query : {search_query}\n",
    "# Instructions:\n",
    "# Share a fun, one liner informative financial fact relating to {search_query} in under 50 words.\n",
    "# This fact can be a piece of advice, a fun fact or a statistic.\n",
    "\n",
    "# Rules:\n",
    "# If the query is a name of a company or brand, generate a financial related fact that is based on the general category of the company or brand.\n",
    "#  Example: If a user searches for \"Starbucks\", generate a financial related fact about coffee.\n",
    "# Do not include the name of the company or brand in the fact.\n",
    "# Provide the source of the fact such as the name of the website or the name of the book.\n",
    "# Do not generate a fact that can negatively impact MoneyLion's brand or reputation.\n",
    "# Do not provide alternatives to MoneyLion's products or services.\n",
    "\n",
    "# Output criteria:\n",
    "#     - return final answer using 3 variables \"generated_fact\", \"source\" and \"fact_type\"\n",
    "#     - compute \"generated_fact\" as: generated fact relating to {search_query}\n",
    "#     - compute \"source\" as: source of the fact\n",
    "#     - compute \"fact_type\" as: type of fact (fun fact, statistic, advice)\n",
    "#     - output final answer in the following format:\n",
    "#         generated_fact=(input value of generated_fact here); source=(input value of source here); fact_type=(input value of fact_type here)\n",
    "# let's think step by step\n",
    "# \"\"\"\n",
    "\n",
    "# EVALUATION_PROMPT = \"\"\"\n",
    "# Here's is a generated fact about {search_query}:\n",
    "# {fact}  \n",
    "\n",
    "# Please evaluate the following sentence for the following criterias:\n",
    "# -Is the fact generated a financial and related to {search_query}?\n",
    "# -Is the source of the fact credible?\n",
    "\n",
    "\n",
    "# Output criteria:\n",
    "#     - return final answer using 4 variables \"result_rating\", \"result_relevance\", \"source_credibility\" and \"rating_reason\"\n",
    "#     - compute \"result_rating\" as: Rate relevance of fact on the scale of 0 to 10, with 0 being not financial fact, and 10 being a useful financial fact\n",
    "#     - compute \"result_relevance\" as: If the fact is relevant to {search_query}, return 1. Else return 0\n",
    "#     - compute \"source_credibility\" as: If the source of the fact is a credible source, return 1. Else return 0\n",
    "#     - compute \"rating_reason\" as: Reasonings of the given score for \"result_rating\", \"result_relevance\" and \"source_credibility\" in detail (in 1-2 sentences)\n",
    "#     - output final answer in the following format: \n",
    "#         result_rating=(input value of result_rating here); result_relevance=(input value of result_relevance here); source_credibility=(input value of source_credibility here); rating_reason=(input value of rating_reason here)\n",
    "\n",
    "# let's think step by step\n",
    "# \"\"\"\n",
    "\n",
    "# ENCYCLOPEDIA_PROMPT = \"\"\"\n",
    "# A user searches the following query on the MoneyLion app\n",
    "# search_query : {search_query}\n",
    "# Instructions:\n",
    "# Generate a financial related fact relating to the search query in under 50 words.\n",
    "# This fact can be a piece of advice, a fun fact or a statistic.\n",
    "# Provide the source of the fact such as the name of the website or the name of the book.\n",
    "\n",
    "# The output must adhere to the following rules:\n",
    "#     Do not produce a fact that can negatively impact MoneyLion's brand or reputation.\n",
    "#     Do not provide alternatives to MoneyLion's products or services.\n",
    "#     The output must not contain any company names or brand names.\n",
    "\n",
    "# Output criteria:\n",
    "#     - return final answer using 4 variables \"generated_fact\", \"category\", \"source\" and \"fact_type\"\n",
    "#     - compute \"generated_fact\" as: generated fact relating to category of {search_query}\n",
    "#     - compute \"category\" as: category of {search_query}\n",
    "#     - compute \"source\" as: source of the fact\n",
    "#     - compute \"fact_type\" as: type of fact (fun fact, statistic, advice)\n",
    "#     - output final answer in the following format:\n",
    "#         generated_fact=(input value of generated_fact here); category=(input value of category here); source=(input value of source here); fact_type=(input value of fact_type here)\n",
    "\n",
    "# Use the examples below as a reference to generate the output.\n",
    "# Examples:\n",
    "# search_query : \"Pizza Hut\"\n",
    "# output : generated_fact=The global fast food industry is estimated to reach a value of $931 billion by 2027, driven by factors like convenience, affordability, and changing consumer preferences.; category= \"fast food\"; source=MarketResearch.com - \"Global Fast Food Market Size, Share & Trends Analysis Report By Product Type (Burger/Sandwich, Pizza/Pasta, Chicken, Asian/Latin American Food, Sea-Food, Others), And Segment Forecasts, 2020 - 2027\"; fact_type=Statistic\n",
    "\n",
    "# search_query : \"Starbucks\"\n",
    "# output : generated_fact=Coffee is the second most traded commodity in the world after oil, with around 2.25 billion cups of coffee consumed globally every day.; category = \"coffee\"; source=International Coffee Organization; fact_type=Statistic\n",
    "\n",
    "# search_query : \"Chime\"\n",
    "# output : generated_fact=\"On average, it takes only 3 minutes to open a bank account online.\"; category=\"banking\"; source=\"ValuePenguin\"; fact_type=\"statistic\"\n",
    "# \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai_srch_summarization_p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
